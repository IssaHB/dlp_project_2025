{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Model I Galaxy Classifier (Spiral, Elliptical, Odd objects)\n",
        "\n",
        "**Most of this code is made by the authors of the paper of Ghaderi et al. (2025) (https://iopscience.iop.org/article/10.3847/1538-4365/ada8ab) and taken from the GitHub Repository: https://github.com/hmddev1/machine_learning_for_morphological_galaxy_classification**\n",
        "\n",
        "**This notebook classifies the images of galaxies to spiral and elliptical galaxies and odd objects using the Zernike Moments and the SVM (Model I).**\n",
        "\n",
        "**Purpose of this notebook: Run Model I for 10 iterations, and obtain results to reproduce table 4 of Ghaderi et al. (2025).**"
      ],
      "metadata": {
        "id": "r4pii4wpL1hU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/Shared drives/DLP Project/Project/Models/Galaxy Models/Looping each Model'\n",
        "os.chdir(path)\n",
        "%run imports.py\n",
        "%matplotlib inline\n",
        "import plotting\n",
        "roc_curves = {}\n",
        "\n",
        "# Paths to images\n",
        "spath = r'/content/drive/Shared drives/DLP Project/Project/Data/galaxy/images/cropped_spiral'\n",
        "epath = r'/content/drive/Shared drives/DLP Project/Project/Data/galaxy/images/cropped_elliptical'\n",
        "opath = r'/content/drive/Shared drives/DLP Project/Project/Data/galaxy/images/cropped_odd'\n",
        "\n",
        "# Default image size and zernike order.\n",
        "image_size = 200\n",
        "zernike_order = 45\n",
        "\n",
        "# Loading the ZMs and concatenating to a consolidated dataset\n",
        "spiral_data = pd.read_csv('/content/drive/Shared drives/DLP Project/Project/spiral_zms.csv')\n",
        "elliptical_data = pd.read_csv('/content/drive/Shared drives/DLP Project/Project/elliptical_zms.csv')\n",
        "odd_data = pd.read_csv('/content/drive/Shared drives/DLP Project/Project/odd_zms.csv')\n",
        "\n",
        "spiral_data.drop(\"Unnamed: 0\", axis = 1, inplace = True)\n",
        "elliptical_data.drop(\"Unnamed: 0\", axis = 1, inplace = True)\n",
        "odd_data.drop(\"Unnamed: 0\", axis = 1, inplace = True)\n",
        "\n",
        "all_zm_data = np.concatenate([spiral_data, elliptical_data, odd_data])\n",
        "np.shape(all_zm_data)\n",
        "\n",
        "spiral_label = [0] * len(spiral_data)\n",
        "elliptical_label = [1] * len(elliptical_data)\n",
        "odd_label = [2] * len(odd_data)\n",
        "\n",
        "all_labels = np.concatenate([spiral_label, elliptical_label, odd_label])\n",
        "len(all_labels)"
      ],
      "metadata": {
        "id": "EXBGZRL7EHz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_iterations = 10\n",
        "metrics_list = []  # Store metrics for each iteration\n",
        "\n",
        "for iteration in range(num_iterations):\n",
        "    print(f\"Iteration {iteration + 1}...\")\n",
        "\n",
        "    X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(\n",
        "        all_zm_data, all_labels, np.arange(len(all_labels)),\n",
        "        test_size=0.25, shuffle=True, random_state=None)\n",
        "\n",
        "    class_weights = {0: len(all_zm_data) / (3 * len(spiral_data)),\n",
        "                     1: len(all_zm_data) / (3 * len(elliptical_data)),\n",
        "                     2: len(all_zm_data) / (3 * len(odd_data))}\n",
        "\n",
        "    # Training model\n",
        "    model = SVC(kernel='rbf', probability=True, C=1.5, gamma='scale', class_weight=class_weights)\n",
        "    gz2_training_model = model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = gz2_training_model.predict(X_test)\n",
        "    y_score = gz2_training_model.predict_proba(X_test)\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    # Performance metrics (per-class)\n",
        "    recall_per_class = recall_score(y_test, y_pred, average=None)\n",
        "    precision_per_class = precision_score(y_test, y_pred, average=None)\n",
        "    f1_per_class = f1_score(y_test, y_pred, average=None)\n",
        "    accuracy = accuracy_score(y_test, y_pred) # overall\n",
        "\n",
        "    # Compute per-class TSS\n",
        "    tss_per_class = {}\n",
        "    for i, class_name in enumerate(['Spiral', 'Elliptical', 'Odd']):\n",
        "        tp = cm[i, i]\n",
        "        fn = np.sum(cm[i, :]) - tp\n",
        "        fp = np.sum(cm[:, i]) - tp\n",
        "        tn = np.sum(cm) - (tp + fn + fp)\n",
        "        tss_per_class[class_name] = (tp / (tp + fn + 1e-6)) - (fp / (fp + tn + 1e-6))\n",
        "\n",
        "    # Storing metrics in the list\n",
        "    metrics_list.append({\n",
        "        'Iteration': iteration + 1,\n",
        "        'Recall per Class': recall_per_class,\n",
        "        'Precision per Class': precision_per_class,\n",
        "        'F1 per Class': f1_per_class,\n",
        "        'Accuracy': accuracy,\n",
        "        'TSS per Class': tss_per_class\n",
        "    })\n",
        "\n",
        "for result in metrics_list:\n",
        "    print(result)\n"
      ],
      "metadata": {
        "id": "C3s13jI6TbO-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}